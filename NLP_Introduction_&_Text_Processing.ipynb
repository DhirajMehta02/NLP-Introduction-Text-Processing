{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  NLP Introduction & Text Processing"
      ],
      "metadata": {
        "id": "xx43ObPUBhde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Computational Linguistics and how does it relate to NLP?\n",
        "\n",
        "\n",
        "Answer: Computational Linguistics (CL) is an interdisciplinary field that deals with the computational aspects of human language. It involves applying computer science techniques to analyze, understand, and generate natural language.\n",
        "\n",
        "Natural Language Processing (NLP) is a subfield within Artificial Intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language.\n",
        "\n",
        "Relationship between CL and NLP:\n",
        "\n",
        "Foundation: Computational Linguistics provides the theoretical and methodological foundations for NLP. It develops the formalisms, models, and algorithms necessary for processing language computationally.\n",
        "Application: NLP takes these theoretical underpinnings and applies them to practical problems, such as machine translation, sentiment analysis, spam detection, and chatbots.\n",
        "Overlap: There is a significant overlap, and sometimes the terms are used interchangeably. However, CL is generally more concerned with the linguistic theories and models, while NLP is more focused on the engineering and application aspects of building systems that can interact with human language."
      ],
      "metadata": {
        "id": "71ei5gDiBqGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Briefly describe the historical evolution of Natural Language Processing.\n",
        "\n",
        "\n",
        "Answer: Natural Language Processing (NLP) has evolved through several distinct phases:\n",
        "\n",
        "Symbolic NLP (1950s - early 1990s): Early approaches relied heavily on hand-crafted rules, grammars, and lexicons. Examples include ELIZA (1966) and SHRDLU (1970s). These systems were brittle and struggled with ambiguity.\n",
        "\n",
        "Statistical NLP (late 1980s - 2000s): With the rise of machine learning, this era focused on probabilistic models like Hidden Markov Models (HMMs) and Naive Bayes, using large text corpora. Feature engineering was a key aspect.\n",
        "\n",
        "Machine Learning & Neural Networks (2000s - early 2010s): More sophisticated ML algorithms (e.g., SVMs) were applied. The introduction of word embeddings (e.g., Word2Vec) was a significant development, capturing semantic relationships.\n",
        "\n",
        "Deep Learning & Neural NLP (mid-2010s - Present): This phase saw the rise of Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTMs), and Convolutional Neural Networks (CNNs). Breakthroughs came with attention mechanisms and, crucially, Transformer models (from 2017 onwards) like BERT, GPT, and T5. These models, often pre-trained on massive datasets, led to the development of today's powerful Large Language Models (LLMs), demonstrating advanced abilities in understanding, generating, and reasoning with human language."
      ],
      "metadata": {
        "id": "M8RjgnpWCEiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: List and explain three major use cases of NLP in today’s tech industry.\n",
        "\n",
        "\n",
        "Answer: Sentiment Analysis/Opinion Mining: This involves analyzing text to determine the emotional tone, sentiment (positive, negative, neutral), or subjective opinions expressed within it. Companies use NLP to process customer reviews, social media posts, and survey responses to understand public perception of their products or services. It helps in market research, brand management, and identifying areas for improvement.\n",
        "\n",
        "Chatbots and Virtual Assistants: NLP is fundamental to the operation of chatbots (for customer service, support, sales) and virtual assistants (like Siri, Google Assistant, Alexa). These systems use NLP to understand user queries in natural language, extract intentions and entities, and generate appropriate responses. They enable natural and intuitive human-computer interaction, automating tasks and providing instant information or support.\n",
        "\n",
        "Machine Translation: This is the automatic translation of text or speech from one natural language to another. Modern machine translation systems heavily rely on advanced NLP techniques, particularly neural machine translation (NMT) models. This technology breaks down language barriers in communication, enables global e-commerce, and facilitates access to information across different cultures and languages."
      ],
      "metadata": {
        "id": "7K8AgbCDCxNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is text normalization and why is it essential in text processing tasks?\n",
        "\n",
        "Answer: Text normalization is the process of transforming text into a canonical (standard) form. The goal is to reduce variability in the text data, making it easier for machines to process and understand. It involves several sub-processes that aim to bring different variations of words or characters to a consistent representation.\n",
        "\n",
        "Common examples of text normalization include:\n",
        "\n",
        "Lowercasing: Converting all text to lowercase (e.g., 'Apple', 'apple', 'APPLE' all become 'apple').\n",
        "Tokenization: Breaking down text into smaller units (words, phrases, symbols).\n",
        "Stemming: Reducing words to their root or stem (e.g., 'running', 'runs', 'ran' all become 'run').\n",
        "Lemmatization: Reducing words to their base or dictionary form (lemma), considering vocabulary and morphological analysis (e.g., 'better' becomes 'good', 'caring' becomes 'care').\n",
        "Removing punctuation: Eliminating characters like commas, periods, exclamation marks.\n",
        "Removing stop words: Eliminating common words that carry little semantic meaning (e.g., 'the', 'a', 'is').\n",
        "Handling special characters and numbers: Deciding whether to remove, replace, or standardize them.\n",
        "\n",
        "Text normalization is essential because natural language is highly variable and ambiguous. Without normalization, a machine would treat different forms of the same word (e.g., 'run', 'running', 'ran') as distinct entities, leading to:\n",
        "\n",
        "Improved Consistency: Ensures that variations of the same word or concept are treated uniformly, which is vital for accurate analysis.\n",
        "Reduced Vocabulary Size: By collapsing different forms of words into a single base form, it significantly reduces the overall vocabulary, making models more efficient and less prone to sparsity issues.\n",
        "Enhanced Accuracy: For tasks like sentiment analysis, information retrieval, machine translation, and text classification, normalization helps in accurately matching relevant terms and improving the performance of NLP models.\n",
        "Better Feature Representation: Provides a cleaner, more standardized input for machine learning models, allowing them to learn more meaningful patterns from the text data.\n",
        "Handling Noise: Helps in cleaning up noisy text data by removing irrelevant characters, symbols, or common words that do not contribute much to the meaning.\n"
      ],
      "metadata": {
        "id": "NggJk4LwE-MI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Compare and contrast stemming and lemmatization with suitable\n",
        "examples.\n",
        "\n",
        "Answer: Stemming and lemmatization are both text normalization techniques in Natural Language Processing (NLP) that aim to reduce words to their base or root form to help improve search accuracy and reduce the dimensionality of data.\n",
        "The core difference is that lemmatization uses vocabulary and morphological analysis to ensure the base form (lemma) is a valid, meaningful word, considering the word's context and part of speech. In contrast, stemming uses simpler, faster rule-based algorithms to chop off the ends of words, which may result in a \"stem\" that is not a real dictionary word.\n",
        "\n",
        "**Stemming and lemmatization are both text normalization techniques in Natural Language Processing (NLP), but they differ in approach, accuracy, and linguistic sophistication.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Both techniques aim to reduce words to their base or root form to improve text processing and analysis. However:\n",
        "\n",
        "| Feature              | **Stemming**                                         | **Lemmatization**                                      |\n",
        "|----------------------|------------------------------------------------------|--------------------------------------------------------|\n",
        "| **Definition**        | Removes suffixes/prefixes to get the root form      | Converts word to its dictionary base (lemma)           |\n",
        "| **Method**            | Uses crude heuristics or rules                      | Uses vocabulary and morphological analysis             |\n",
        "| **Accuracy**          | Less accurate, may produce non-words                | More accurate, always returns valid words              |\n",
        "| **Speed**             | Faster, simpler                                     | Slower, computationally intensive                      |\n",
        "| **Example**           | “running” → “run”, “flies” → “fli”                  | “running” → “run”, “flies” → “fly”                     |\n",
        "| **Use Case**          | Quick search engines, large-scale indexing          | Chatbots, machine translation, semantic analysis       |\n",
        "\n",
        "---\n",
        "\n",
        "### Examples\n",
        "\n",
        "\n",
        "| **Original Word** | **Stemming Result** | **Lemmatization Result** |\n",
        "|-------------------|---------------------|---------------------------|\n",
        "| caring            | car                 | care                      |\n",
        "| better            | better              | good                      |\n",
        "| studies           | studi               | study                     |\n",
        "| went              | went                | go                        |\n",
        "\n",
        "- **Stemming** often chops off endings without understanding context (e.g., “studies” → “studi”).\n",
        "- **Lemmatization** uses context and grammar (e.g., “went” → “go”, recognizing it as past tense).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "QdgEKYwUFa6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program that uses regular expressions (regex) to extract all\n",
        "email addresses from the following block of text:\n",
        "“Hello team, please contact us at support@xyz.com for technical issues, or reach out to\n",
        "our HR at hr@xyz.com. You can also connect with John at john.doe@xyz.org and jenny\n",
        "via jenny_clarke126@mail.co.us. For partnership inquiries, email partners@xyz.biz.”\n",
        "\n",
        "Ans:\n"
      ],
      "metadata": {
        "id": "8w9a-FJCGZls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Input text\n",
        "text = \"\"\"\n",
        "Hello team, please contact us at support@xyz.com for technical issues, or reach out to\n",
        "our HR at hr@xyz.com. You can also connect with John at john.doe@xyz.org and jenny\n",
        "via jenny_clarke126@mail.co.us. For partnership inquiries, email partners@xyz.biz.\n",
        "\"\"\"\n",
        "\n",
        "# Regular expression pattern for email addresses\n",
        "email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
        "\n",
        "# Find all matches\n",
        "emails = re.findall(email_pattern, text)\n",
        "\n",
        "# Print the extracted email addresses\n",
        "print(\"Extracted email addresses:\")\n",
        "for email in emails:\n",
        "    print(email)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYZcjL-iGmzc",
        "outputId": "9d6b2444-eb09-4ccc-caa9-12bb060e5587"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted email addresses:\n",
            "support@xyz.com\n",
            "hr@xyz.com\n",
            "john.doe@xyz.org\n",
            "jenny_clarke126@mail.co.us\n",
            "partners@xyz.biz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Given the sample paragraph below, perform string tokenization and\n",
        "frequency distribution using Python and NLTK:\n",
        "“Natural Language Processing (NLP) is a fascinating field that combines linguistics,\n",
        "computer science, and artificial intelligence. It enables machines to understand,\n",
        "interpret, and generate human language. Applications of NLP include chatbots,\n",
        "sentiment analysis, and machine translation. As technology advances, the role of NLP\n",
        "in modern solutions is becoming increasingly critical.”"
      ],
      "metadata": {
        "id": "yy0dfbtzGwca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Sample paragraph\n",
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is a fascinating field that combines linguistics,\n",
        "computer science, and artificial intelligence. It enables machines to understand,\n",
        "interpret, and generate human language. Applications of NLP include chatbots,\n",
        "sentiment analysis, and machine translation. As technology advances, the role of NLP\n",
        "in modern solutions is becoming increasingly critical.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Frequency Distribution\n",
        "fdist = FreqDist(tokens)\n",
        "\n",
        "# Display results\n",
        "print(\"Tokenized Words:\")\n",
        "print(tokens)\n",
        "print(\"\\nFrequency Distribution:\")\n",
        "for word, freq in fdist.most_common(10):\n",
        "    print(f\"{word}: {freq}\")"
      ],
      "metadata": {
        "id": "vpwl3tx6HwbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Create a custom annotator using spaCy or NLTK that identifies and labels\n",
        "proper nouns in a given text."
      ],
      "metadata": {
        "id": "R5hbpNibH4-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"SpaCy English model not found. Please run the previous cell to download it.\")\n",
        "    print(\"python -m spacy download en_core_web_sm\")\n",
        "    exit()\n",
        "\n",
        "def custom_proper_noun_annotator(text):\n",
        "    \"\"\"\n",
        "    Identifies and labels proper nouns in a given text using spaCy's NER.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    proper_nouns = []\n",
        "    for ent in doc.ents:\n",
        "        # spaCy's NER labels for common proper nouns include PERSON, ORG, GPE, LOC, etc.\n",
        "        # You can customize this list based on what you consider a 'proper noun'.\n",
        "        if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"LOC\", \"NORP\", \"FAC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\", \"LANGUAGE\", \"DATE\", \"TIME\", \"MONEY\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\"]:\n",
        "            proper_nouns.append({\"text\": ent.text, \"label\": ent.label_})\n",
        "    return proper_nouns\n",
        "\n",
        "# Sample Text\n",
        "sample_text = \"Google was founded by Larry Page and Sergey Brin. It is headquartered in Mountain View, California, and has offices around the world, including London and New York. The company also developed the Android operating system.\"\n",
        "\n",
        "# Annotate the text\n",
        "annotations = custom_proper_noun_annotator(sample_text)\n",
        "\n",
        "print(\"Proper Noun Annotations:\")\n",
        "if annotations:\n",
        "    for pn in annotations:\n",
        "        print(f\"- Text: '{pn['text']}', Label: '{pn['label']}'\")\n",
        "else:\n",
        "    print(\"No proper nouns identified.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxlrtaodIH5D",
        "outputId": "ee7acff6-9643-44ea-9e23-1a4903fa0717"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proper Noun Annotations:\n",
            "- Text: 'Google', Label: 'ORG'\n",
            "- Text: 'Larry Page', Label: 'PERSON'\n",
            "- Text: 'Sergey Brin', Label: 'PERSON'\n",
            "- Text: 'Mountain View', Label: 'GPE'\n",
            "- Text: 'California', Label: 'GPE'\n",
            "- Text: 'London', Label: 'GPE'\n",
            "- Text: 'New York', Label: 'GPE'\n",
            "- Text: 'Android', Label: 'ORG'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Using Genism, demonstrate how to train a simple Word2Vec model on the\n",
        "following dataset consisting of example sentences:\n",
        "dataset = [\n",
        " \"Natural language processing enables computers to understand human language\",\n",
        " \"Word embeddings are a type of word representation that allows words with similar\n",
        "meaning to have similar representation\",\n",
        " \"Word2Vec is a popular word embedding technique used in many NLP applications\",\n",
        " \"Text preprocessing is a critical step before training word embeddings\",\n",
        " \"Tokenization and normalization help clean raw text for modeling\"\n",
        "]\n",
        "Write code that tokenizes the dataset, preprocesses it, and trains a Word2Vec model using\n",
        "Gensim.\n"
      ],
      "metadata": {
        "id": "d3RirgYMIHst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "# Download tokenizer resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample dataset\n",
        "dataset = [\n",
        "    \"Natural language processing enables computers to understand human language\",\n",
        "    \"Word embeddings are a type of word representation that allows words with similar meaning to have similar representation\",\n",
        "    \"Word2Vec is a popular word embedding technique used in many NLP applications\",\n",
        "    \"Text preprocessing is a critical step before training word embeddings\",\n",
        "    \"Tokenization and normalization help clean raw text for modeling\"\n",
        "]\n",
        "\n",
        "# Preprocessing: lowercase, tokenize, remove punctuation\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "# Tokenize and preprocess each sentence\n",
        "processed_data = [preprocess(sentence) for sentence in dataset]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=processed_data, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Example: find most similar words to 'word'\n",
        "similar_words = model.wv.most_similar('word', topn=5)\n",
        "print(\"Words similar to 'word':\")\n",
        "for word, score in similar_words:\n",
        "    print(f\"{word}: {score:.4f}\")"
      ],
      "metadata": {
        "id": "QmApzDTqItPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you are a data scientist at a fintech startup. You’ve been tasked\n",
        "with analyzing customer feedback. Outline the steps you would take to clean, process,\n",
        "and extract useful insights using NLP techniques from thousands of customer reviews\n",
        "\n",
        "Ans: **To analyze customer feedback using NLP at a fintech startup, you would follow a structured pipeline involving data cleaning, preprocessing, modeling, and insight extraction. This ensures accurate sentiment analysis, topic detection, and actionable recommendations.**\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Data Collection & Cleaning\n",
        "\n",
        "- **Source**: Gather reviews from platforms like app stores, surveys, emails, or support tickets.\n",
        "- **Remove noise**: Strip HTML tags, emojis, special characters, and irrelevant metadata.\n",
        "- **Handle missing data**: Drop or impute null entries.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Text Preprocessing\n",
        "\n",
        "- **Lowercasing**: Normalize text for uniformity.\n",
        "- **Tokenization**: Split text into words or phrases using tools like NLTK or SpaCy.\n",
        "- **Stopword removal**: Eliminate common words (e.g., “the”, “is”) that don’t add meaning.\n",
        "- **Stemming/Lemmatization**: Reduce words to their root form (e.g., “running” → “run”) for consistency.\n",
        "- **Spelling correction**: Use libraries like `TextBlob` or `SymSpell` to fix typos.\n",
        "- **Named Entity Recognition (NER)**: Identify entities like bank names, transaction types, or locations.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Exploratory Data Analysis (EDA)\n",
        "\n",
        "- **Word frequency**: Identify common terms using `FreqDist` or `Counter`.\n",
        "- **N-grams**: Extract frequent phrases (e.g., “credit card”, “loan approval”).\n",
        "- **Word clouds**: Visualize dominant themes.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Sentiment Analysis\n",
        "\n",
        "- **Lexicon-based**: Use tools like VADER or TextBlob for polarity scores.\n",
        "- **Model-based**: Train classifiers (e.g., logistic regression, BERT) to detect positive, negative, or neutral sentiment.\n",
        "- **Use case**: Understand customer satisfaction, detect frustration, or praise.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Topic Modeling\n",
        "\n",
        "- **LDA (Latent Dirichlet Allocation)**: Discover hidden topics in reviews (e.g., “customer service”, “app usability”).\n",
        "- **Clustering**: Group similar feedback using K-means or DBSCAN.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Keyword & Intent Extraction\n",
        "\n",
        "- **TF-IDF**: Identify unique and important terms.\n",
        "- **Dependency parsing**: Understand relationships between words (e.g., “delay in payment”).\n",
        "- **Intent classification**: Categorize feedback into intents like complaint, suggestion, or praise.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Visualization & Reporting\n",
        "\n",
        "- **Dashboards**: Use tools like Power BI or Tableau to present insights.\n",
        "- **Trend analysis**: Track sentiment or topic shifts over time.\n",
        "- **Alerts**: Flag critical feedback (e.g., fraud mentions) for immediate action.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. Automation & Deployment\n",
        "\n",
        "- **Pipeline**: Build an automated NLP workflow using Python, Airflow, or cloud services.\n",
        "- **Model retraining**: Periodically update models with new data.\n",
        "- **Integration**: Feed insights into CRM or product development tools.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "UbcpvmfTIzXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TfTsR4b5JCDU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAkiDH1cIwIX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}